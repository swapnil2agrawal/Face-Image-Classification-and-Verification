{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from recitation-6\n",
    "imageFolder_dataset = torchvision.datasets.ImageFolder(root='./train_data/medium/', \n",
    "                                                       transform=torchvision.transforms.ToTensor())\n",
    "imageFolder_dataloader = DataLoader(imageFolder_dataset, batch_size=1, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverted Residual Block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have taken MobileNetV2 implementation from this gitHub repository\n",
    "https://github.com/pytorch/vision/blob/master/torchvision/models/mobilenet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBNReLU(nn.Sequential):\n",
    "    def __init__(self, in_planes, out_planes, kernel_size=3, stride=1, groups=1):\n",
    "        padding = (kernel_size - 1) // 2\n",
    "        super(ConvBNReLU, self).__init__(\n",
    "            nn.Conv2d(in_planes, out_planes, kernel_size, stride, padding, groups=groups, bias=False),\n",
    "            nn.BatchNorm2d(out_planes),\n",
    "            nn.ReLU6(inplace=True)\n",
    "        )\n",
    "\n",
    "\n",
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, inp, oup, stride, expand_ratio):\n",
    "        super(InvertedResidual, self).__init__()\n",
    "        self.stride = stride\n",
    "        assert stride in [1, 2]\n",
    "\n",
    "        hidden_dim = int(round(inp * expand_ratio))\n",
    "        self.use_res_connect = self.stride == 1 and inp == oup\n",
    "\n",
    "        layers = []\n",
    "        if expand_ratio != 1:\n",
    "            # pw\n",
    "            layers.append(ConvBNReLU(inp, hidden_dim, kernel_size=1))\n",
    "        layers.extend([\n",
    "            # dw\n",
    "            ConvBNReLU(hidden_dim, hidden_dim, stride=stride, groups=hidden_dim),\n",
    "            # pw-linear\n",
    "            nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(oup),\n",
    "        ])\n",
    "        self.conv = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.conv(x)\n",
    "        else:\n",
    "            return self.conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobile Net Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MobileNetV2(nn.Module):\n",
    "    def __init__(self, input_channel, num_classes, width_mult=1.0, inverted_residual_setting=None):\n",
    "        \n",
    "        super(MobileNetV2, self).__init__()\n",
    "        block = InvertedResidual\n",
    "        \n",
    "        if inverted_residual_setting is None:\n",
    "            inverted_residual_setting = [\n",
    "                # t, c, n, s\n",
    "                [1, 64, 2, 2],\n",
    "                [6, 128, 4, 2],\n",
    "                [6, 256, 6, 1],\n",
    "            ]\n",
    "\n",
    "        self.last_channel = 1280\n",
    "        features = []\n",
    "        \n",
    "        # building inverted residual blocks\n",
    "        for t, c, n, s in inverted_residual_setting:\n",
    "            output_channel = c\n",
    "            for i in range(n):\n",
    "                stride = s if i == 0 else 1\n",
    "                features.append(block(input_channel, output_channel, stride, expand_ratio=t))\n",
    "                input_channel = output_channel\n",
    "                \n",
    "        # building last several layers\n",
    "        features.append(ConvBNReLU(input_channel, self.last_channel, kernel_size=1))\n",
    "        \n",
    "        # make it nn.Sequential\n",
    "        self.features = nn.Sequential(*features)\n",
    "\n",
    "        # building classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(self.last_channel, num_classes),\n",
    "        )\n",
    "\n",
    "        # weight initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.xavier_normal_(m.weight.data)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.ones_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "#         print(x.shape)\n",
    "        x = x.mean([2, 3])\n",
    "        x = self.classifier(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(3, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=3, bias=False)\n",
       "          (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace)\n",
       "        )\n",
       "        (1): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace)\n",
       "        )\n",
       "        (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace)\n",
       "        )\n",
       "        (2): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace)\n",
       "        )\n",
       "        (2): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace)\n",
       "        )\n",
       "        (2): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace)\n",
       "        )\n",
       "        (2): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(128, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)\n",
       "          (1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace)\n",
       "        )\n",
       "        (2): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace)\n",
       "        )\n",
       "        (2): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace)\n",
       "        )\n",
       "        (2): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace)\n",
       "        )\n",
       "        (2): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace)\n",
       "        )\n",
       "        (2): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNReLU(\n",
       "          (0): Conv2d(256, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace)\n",
       "        )\n",
       "        (1): ConvBNReLU(\n",
       "          (0): Conv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1536, bias=False)\n",
       "          (1): BatchNorm2d(1536, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace)\n",
       "        )\n",
       "        (2): Conv2d(1536, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): ConvBNReLU(\n",
       "      (0): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2)\n",
       "    (1): Linear(in_features=1280, out_features=2300, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MobileNetV2(3, 2300)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save only model parameters\n",
    "PATH = \"./basic_cnn_trial2_100.pt\"\n",
    "model = MobileNetV2(3, 2300)\n",
    "model.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have taken this implementation from recitation-6 and have made changes according to this assignment's requirement\n",
    "\n",
    "def train(model, data_loader, test_loader, task='Classification'):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(numEpochs):\n",
    "        start = time.time()\n",
    "        avg_loss = 0.0\n",
    "        \n",
    "        accuracy = 0\n",
    "        total = 0\n",
    "        \n",
    "        for batch_num, (feats, labels) in enumerate(data_loader):\n",
    "            feats, labels = feats.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(feats)\n",
    "            \n",
    "            loss = criterion(outputs, labels.long())\n",
    "            loss.backward()\n",
    "            optimizer.step()          \n",
    "            avg_loss += loss.item()\n",
    "       \n",
    "            if batch_num % 500 == 499:\n",
    "                print('Epoch: {}\\tBatch: {}\\tAvg-Loss: {:.4f}'.format(epoch+1, batch_num+1, avg_loss/500))\n",
    "                avg_loss = 0.0\n",
    "            \n",
    "            torch.cuda.empty_cache()\n",
    "            del feats\n",
    "            del labels\n",
    "            del loss\n",
    "            \n",
    "        if task == 'Classification':\n",
    "            val_loss, val_acc = test_classify(model, test_loader)\n",
    "            train_loss, train_acc = test_classify(model, data_loader)\n",
    "            print('Train Loss: {:.4f}\\tTrain Accuracy: {:.4f}\\tVal Loss: {:.4f}\\tVal Accuracy: {:.4f}'.\n",
    "                  format(train_loss, train_acc, val_loss, val_acc))\n",
    "        else:\n",
    "            test_verify(model, test_loader)\n",
    "            \n",
    "        print(\"time: \", time.time()-start)\n",
    "        PATH = \"./new_\" + str(epoch + 100) + \".pt\"\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "\n",
    "def test_classify(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = []\n",
    "    accuracy = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_num, (feats, labels) in enumerate(test_loader):\n",
    "        feats, labels = feats.to(device), labels.to(device)\n",
    "        outputs = model(feats)\n",
    "        \n",
    "#         print(\"...\", outputs.shape)\n",
    "        pred_labels = torch.max(F.softmax(outputs, dim=1), 1)[1]\n",
    "        pred_labels = pred_labels.view(-1)\n",
    "#         print(pred_labels)\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        \n",
    "        accuracy += torch.sum(torch.eq(pred_labels, labels)).item()\n",
    "        total += len(labels)\n",
    "        test_loss.extend([loss.item()]*feats.size()[0])\n",
    "        del feats\n",
    "        del labels\n",
    "\n",
    "    model.train()\n",
    "    return np.mean(test_loss), 100*accuracy/total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.ImageFolder(root='./train_data/medium/', \n",
    "                                                 transform=torchvision.transforms.ToTensor())\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=100, \n",
    "                                               shuffle=True, num_workers=8)\n",
    "\n",
    "dev_dataset = torchvision.datasets.ImageFolder(root='./validation_classification/medium/', \n",
    "                                               transform=torchvision.transforms.ToTensor())\n",
    "dev_dataloader = torch.utils.data.DataLoader(dev_dataset, batch_size=100, \n",
    "                                             shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numEpochs = 30\n",
    "learningRate = 1e-4\n",
    "weightDecay = 5e-5\n",
    " \n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr =0.01)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learningRate, weight_decay=weightDecay, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\tBatch: 500\tAvg-Loss: 0.2731\n",
      "Epoch: 1\tBatch: 1000\tAvg-Loss: 0.2649\n",
      "Epoch: 1\tBatch: 1500\tAvg-Loss: 0.2643\n",
      "Epoch: 1\tBatch: 2000\tAvg-Loss: 0.2755\n",
      "Epoch: 1\tBatch: 2500\tAvg-Loss: 0.2673\n",
      "Epoch: 1\tBatch: 3000\tAvg-Loss: 0.2638\n",
      "Epoch: 1\tBatch: 3500\tAvg-Loss: 0.2646\n",
      "Epoch: 1\tBatch: 4000\tAvg-Loss: 0.2641\n",
      "Epoch: 1\tBatch: 4500\tAvg-Loss: 0.2636\n",
      "Epoch: 1\tBatch: 5000\tAvg-Loss: 0.2629\n",
      "Epoch: 1\tBatch: 5500\tAvg-Loss: 0.2677\n",
      "Epoch: 1\tBatch: 6000\tAvg-Loss: 0.2670\n",
      "Epoch: 1\tBatch: 6500\tAvg-Loss: 0.2636\n",
      "Epoch: 1\tBatch: 7000\tAvg-Loss: 0.2578\n",
      "Epoch: 1\tBatch: 7500\tAvg-Loss: 0.2668\n",
      "Epoch: 1\tBatch: 8000\tAvg-Loss: 0.2607\n",
      "Train Loss: 0.1680\tTrain Accuracy: 96.9563\tVal Loss: 1.0528\tVal Accuracy: 78.0048\n",
      "time:  1728.1768281459808\n",
      "Epoch: 2\tBatch: 500\tAvg-Loss: 0.2554\n",
      "Epoch: 2\tBatch: 1000\tAvg-Loss: 0.2576\n",
      "Epoch: 2\tBatch: 1500\tAvg-Loss: 0.2614\n",
      "Epoch: 2\tBatch: 2000\tAvg-Loss: 0.2614\n",
      "Epoch: 2\tBatch: 2500\tAvg-Loss: 0.2621\n",
      "Epoch: 2\tBatch: 3000\tAvg-Loss: 0.2568\n",
      "Epoch: 2\tBatch: 3500\tAvg-Loss: 0.2543\n",
      "Epoch: 2\tBatch: 4000\tAvg-Loss: 0.2593\n",
      "Epoch: 2\tBatch: 4500\tAvg-Loss: 0.2574\n",
      "Epoch: 2\tBatch: 5000\tAvg-Loss: 0.2615\n",
      "Epoch: 2\tBatch: 5500\tAvg-Loss: 0.2563\n",
      "Epoch: 2\tBatch: 6000\tAvg-Loss: 0.2575\n",
      "Epoch: 2\tBatch: 6500\tAvg-Loss: 0.2521\n",
      "Epoch: 2\tBatch: 7000\tAvg-Loss: 0.2570\n",
      "Epoch: 2\tBatch: 7500\tAvg-Loss: 0.2561\n",
      "Epoch: 2\tBatch: 8000\tAvg-Loss: 0.2614\n",
      "Train Loss: 0.1635\tTrain Accuracy: 97.0720\tVal Loss: 1.0549\tVal Accuracy: 78.1569\n",
      "time:  2234.9438829421997\n",
      "Epoch: 3\tBatch: 500\tAvg-Loss: 0.2512\n",
      "Epoch: 3\tBatch: 1000\tAvg-Loss: 0.2447\n",
      "Epoch: 3\tBatch: 1500\tAvg-Loss: 0.2559\n",
      "Epoch: 3\tBatch: 2000\tAvg-Loss: 0.2567\n",
      "Epoch: 3\tBatch: 2500\tAvg-Loss: 0.2546\n",
      "Epoch: 3\tBatch: 3000\tAvg-Loss: 0.2549\n",
      "Epoch: 3\tBatch: 3500\tAvg-Loss: 0.2509\n",
      "Epoch: 3\tBatch: 4000\tAvg-Loss: 0.2518\n",
      "Epoch: 3\tBatch: 4500\tAvg-Loss: 0.2552\n",
      "Epoch: 3\tBatch: 5000\tAvg-Loss: 0.2588\n",
      "Epoch: 3\tBatch: 5500\tAvg-Loss: 0.2483\n",
      "Epoch: 3\tBatch: 6000\tAvg-Loss: 0.2507\n",
      "Epoch: 3\tBatch: 6500\tAvg-Loss: 0.2505\n",
      "Epoch: 3\tBatch: 7000\tAvg-Loss: 0.2515\n",
      "Epoch: 3\tBatch: 7500\tAvg-Loss: 0.2491\n",
      "Epoch: 3\tBatch: 8000\tAvg-Loss: 0.2522\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2fd28d8c1c3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-3e31af35a033>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, data_loader, test_loader, task)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Classification'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             print('Train Loss: {:.4f}\\tTrain Accuracy: {:.4f}\\tVal Loss: {:.4f}\\tVal Accuracy: {:.4f}'.\n\u001b[1;32m     37\u001b[0m                   format(train_loss, train_acc, val_loss, val_acc))\n",
      "\u001b[0;32m<ipython-input-10-3e31af35a033>\u001b[0m in \u001b[0;36mtest_classify\u001b[0;34m(model, test_loader)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0maccuracy\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mtest_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfeats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "model.to(device)\n",
    "train(model, train_dataloader, dev_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "model.to(device)\n",
    "train(model, train_dataloader, dev_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"./basic_cnn2.pt\"\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapkv = imageFolder_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {v:k for k,v in mapkv.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classify_closs(model, test_loader):\n",
    "    label = []\n",
    "    model.eval()\n",
    "    k =0 \n",
    "    for batch_num, (feats, labels) in enumerate(test_loader):\n",
    "#         print(k)\n",
    "        feats, labels = feats.to(device), labels.to(device)\n",
    "        outputs = model(feats)\n",
    "        \n",
    "        pred_labels = torch.max(F.softmax(outputs, dim=1), 1)[1]\n",
    "        pred_labels = pred_labels.view(-1)\n",
    "        k += 1\n",
    "        y_cap = pred_labels[0].item()\n",
    "        \n",
    "        label.append(mapping[y_cap])\n",
    "        \n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.ImageFolder(root='./test_classification/', \n",
    "                                                 transform=torchvision.transforms.ToTensor())\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating output\n",
    "\n",
    "model.to(device)\n",
    "output = test_classify_closs(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=submission.csv>Download CSV file</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to download csv file\n",
    "\n",
    "from IPython.display import HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame(np.array(output), columns=['label'])\n",
    "df.to_csv('submission.csv')\n",
    "def create_download_link(title = \"Download CSV file\", filename = \"data.csv\"):\n",
    "    html = '<a href={filename}>{title}</a>'\n",
    "    html = html.format(title=title,filename=filename)\n",
    "    return HTML(html)\n",
    "# create a link to download the dataframe which was saved with .to_csv method\n",
    "create_download_link(filename='submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
